<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Search Documents</title>
    <style>
        /* Tooltip container */
        .tooltip {
            position: relative;
            display: inline-block;
            cursor: pointer;
        }

        /* Tooltip text */
        .tooltip .tooltiptext {
            visibility: hidden;
            width: 200px;
            background-color: #6c757d;
            color: #fff;
            text-align: center;
            border-radius: 5px;
            padding: 5px;
            position: absolute;
            z-index: 1;
            bottom: 125%; /* Position above the text */
            left: 50%;
            margin-left: -100px; /* Adjust to center the tooltip */
            opacity: 0;
            transition: opacity 0.3s;
        }

        /* Tooltip arrow */
        .tooltip .tooltiptext::after {
            content: "";
            position: absolute;
            top: 100%;
            left: 50%;
            margin-left: -5px;
            border-width: 5px;
            border-style: solid;
            border-color: #6c757d transparent transparent transparent;
        }

        /* Show the tooltip on hover */
        .tooltip:hover .tooltiptext {
            visibility: visible;
            opacity: 1;
        }
    </style>
</head>
<body>
    <h1>Search Documents</h1>
    <form method="POST">
        <label for="query_text">Enter your query:</label><br>
        <input type="text" id="query_text" name="query_text" required><br><br>

        <label for="model_name">Choose model:</label><br>
        <select id="model_name" name="model_name">
            <!-- Display models with tooltips -->
            {% for model in models %}
                <option class="tooltip" value="{{ model }}">
                    {{ model }}
                    <span class="tooltiptext">
                        {% if model == "llama3.1:8b" %}
                            Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.
                        {% elif model == "mistral" %}
                            The 7B model released by Mistral AI, updated to version 0.3.
                        {% elif model == "mistral-nemo" %}
                            A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.
                        {% elif model == "llama3-chatqa:8b" %}
                            A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG). 
                        {% endif %}
                    </span>
                </option>
            {% endfor %}
        </select><br><br>

        <button type="submit">Search</button>
    </form>
</body>
</html>
